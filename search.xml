<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ORB-SLAM学习（一）：ORB特征提取</title>
    <url>/2022/05/05/ORB-SLAM%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/</url>
    <content><![CDATA[<h2 id="相关知识介绍"><a href="#相关知识介绍" class="headerlink" title="相关知识介绍"></a>相关知识介绍</h2><p><a href="https://kxzhang.cn/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/#more">图像金字塔</a></p>
<p><a href="https://kxzhang.cn/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E7%82%B9/">ORB特征点</a></p>
<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><p>ORB-SLAM2中的ORB特征点提取和OpenCV有所不同。在ORB-SLAM2中进行了一系列操作让特征点均匀的分布在图像中，这样对于后面的位姿估计比较好。OpenCV直接提取的特征点可能会出现扎堆，集中等现象，这样很多特征点就没用了。下面对ORB-SLAM2中的ORB特征点提取的过程进行介绍。</p>
<h2 id="构建图像金字塔"><a href="#构建图像金字塔" class="headerlink" title="构建图像金字塔"></a>构建图像金字塔</h2><ul>
<li><p>首先对图像进行扩展，这一步的目的是为了之后的高斯模糊操作。</p>
<p><img src="/2022/05/05/ORB-SLAM%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/图像扩展.png" alt="图像扩充示意，这一步是把原图像（最里边的矩形）扩展到最外侧的矩形"></p>
</li>
<li><p>进行一个循环，把每一层的图像都在上一层图像的基础上进行扩充（或者叫补边），该过程用到了OpenCV中的<em>copyMakeBorder</em>函数和<em>resize</em>函数，扩充的规则为<em>BORDER_REFLECT_101</em>，扩充的效果如下：</p>
</li>
</ul>
<p><img src="/2022/05/05/ORB-SLAM%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/图像扩充.png" alt="左边是扩充效果，可以看出是一个类似镜像的效果"></p>
<h2 id="计算特征点并通过四叉树对特征点进行均匀化操作"><a href="#计算特征点并通过四叉树对特征点进行均匀化操作" class="headerlink" title="计算特征点并通过四叉树对特征点进行均匀化操作"></a>计算特征点并通过四叉树对特征点进行均匀化操作</h2><p>这一步又对每一层进行了一次遍历，干了这些事：</p>
<ul>
<li>把原图像的边扩充3个像素点，这个是为了进行FAST关键点提取预留的计算半径；</li>
<li>把图像均匀划分成了一堆小格子（均匀化）；</li>
<li>对这堆小格子进行遍历，在每个小格子中调用OpenCV中的FAST函数通过yaml文件中的设置阈值进行关键点提取，如果这都没采到哪怕是一个关键点，就采用最低的阈值再采一次；</li>
<li>把采取到的关键点坐标进行转换，之前是在小方格中的坐标系，现在要通过一些偏移操作转换到原图像下的坐标系；</li>
<li>调用<em>DistributeOctTree()</em>函数对特征点进行均匀化（ORB-SLAM的精髓之一），关于四叉树均匀化特征点可以通过下面一幅图来表示；</li>
</ul>
<p><img src="/2022/05/05/ORB-SLAM%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/四叉树.png" alt="四叉树均匀化特征点"></p>
<ul>
<li>再进行一次坐标转换，这次是把提取到的关键点坐标转换为金字塔划分那一步的扩展图像的坐标；</li>
</ul>
<p>干完这些事情后，又进行了一次遍历（写到这才发现这么多遍历，难怪速度比OpenCV的库函数慢）</p>
<ul>
<li>计算特征点的方向信息，调用<em>IC_Angle()</em>函数，通过一些小操作提高了一些速度。</li>
</ul>
<h2 id="计算描述子并进行金字塔图像特征恢复"><a href="#计算描述子并进行金字塔图像特征恢复" class="headerlink" title="计算描述子并进行金字塔图像特征恢复"></a>计算描述子并进行金字塔图像特征恢复</h2><p>这一步一上来又对每层金字塔进行了一次遍历，然后把每层金字塔的特征点个数累加存到了一个变量里，之后根据这个变量设置了描述子矩阵的容量。</p>
<p>再来一次遍历（已经麻了），这一步开始计算描述子</p>
<ul>
<li>首先对金字塔图像进行高斯模糊，因为BRIEF描述子对噪声敏感，所以要通过高斯模糊消除噪声对描述子的影响，这一步就是用到了之前的图像扩充。高斯模糊方法采用的OpenCV函数<em>GaussianBlur()</em>。</li>
<li>然后对每个关键点计算描述子，首先要根据之前计算得到的方向对坐标进行旋转，坐标对其之后根据描述子模板进行描述子计算，保存到<em>descriptors</em>矩阵中；</li>
<li>对于除第0层的图像（也就是最底下那一层），将所有的特征点乘相应层数的缩放因子，投射到最底层图像中，这样就实现了特征点的提取。</li>
</ul>
<h2 id="通过内参矩阵对特征点进行去畸变操作"><a href="#通过内参矩阵对特征点进行去畸变操作" class="headerlink" title="通过内参矩阵对特征点进行去畸变操作"></a>通过内参矩阵对特征点进行去畸变操作</h2><p>内参系数在yaml文件中都给写好了，直接调用OpenCV的库函数<em>undistortPoints()</em>进行特征点去畸变操作。</p>
<h2 id="将特征点分配到网格中"><a href="#将特征点分配到网格中" class="headerlink" title="将特征点分配到网格中"></a>将特征点分配到网格中</h2><p>调用<em>AssignFeaturesToGrid()</em> </p>
]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>ORB-SLAM学习（二）：地图初始化</title>
    <url>/2022/05/08/ORB-SLAM%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9C%B0%E5%9B%BE%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
    <content><![CDATA[<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><p>提取完ORB特征点后，需要对地图进行初始化操作。如果是单目相机，由于图像中不包含深度信息，需要通过连续的几帧图像计算出尺度信息，构建初始的三维点云。如果是双目或RGB-D相机，本身的图像就含有深度信息，因此第一帧的时候就可以完成初始化操作。下面主要对单目相机的初始化进行分析。</p>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p><a href="https://kxzhang.cn/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/#more">基础矩阵，本质矩阵</a></p>
<p><a href="https://kxzhang.cn/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E5%8D%95%E5%BA%94%E7%9F%A9%E9%98%B5/">单应矩阵</a></p>
<p><a href="https://kxzhang.cn/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/#more">奇异值分解</a></p>
<p><a href="https://kxzhang.cn/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/#more">卡方检验</a></p>
<h2 id="地图初始化"><a href="#地图初始化" class="headerlink" title="地图初始化"></a>地图初始化</h2><p>地图初始化在<em>Track()</em>函数中，首先判断<em>mstate</em>有没有初始化,如果没被初始化就根据传感器类型进入不同的初始化函数中，单目初始化函数为<em>MonocularInitialization()</em>，双目或RGB-D相机共用一个初始化函数<em>StereoInitialization()</em>。</p>
<h3 id="StereoInitialization"><a href="#StereoInitialization" class="headerlink" title="StereoInitialization()"></a><em>StereoInitialization()</em></h3><p>首先判断单目初始器<em>mpInitializer</em>有没有被创建，没有并且这一帧图像的特征点数目超过100个，就创建<em>mpInitializer</em>，并且记录参考帧数据。</p>
<p>如果<em>mpInitializer</em>被创建了，但是这一帧的特征点数目没超过100，就删除<em>mpInitializer</em>从头再来。如果一切条件满足，就开始进行特征点匹配，这一步通过<em>SearchForInitialization()</em>函数实现，函数运行完之后<em>mvbPrevMatched</em>存储匹配好的特征点，<em>mvIniMatches</em>是个vector容器，索引值表示参考帧的关键点索引值，索引值对应的值表示当前帧的关键点索引值，通过这个保存特征点的匹配关系。</p>
<p>特征匹配之后调用<em>mpInitializer</em>对象的<em>Initialize()</em>函数进行单目初始化。</p>
<h3 id="成员变量初始化"><a href="#成员变量初始化" class="headerlink" title="成员变量初始化"></a>成员变量初始化</h3><p>遍历一遍匹配好的特征点，把两帧之间匹配好的特征点储存在<em>mvMatches12</em>变量中，把是否匹配成功标志存入<em>mvbMatched1</em>中，成功为true，失败为false。</p>
<h3 id="RANSAC随机采样"><a href="#RANSAC随机采样" class="headerlink" title="RANSAC随机采样"></a>RANSAC随机采样</h3><ul>
<li>设置随机数种子</li>
<li>进行两百次迭代，每次迭代找出随机的八个点，用于后续的八点法求单应矩阵和基础矩阵，把每次找出的特征点索引储存在<em>mvSets</em>中，之后从待搜索的范围内删除该特征点的索引，确保不会被重复采集到</li>
</ul>
<h3 id="计算基础矩阵F和单应矩阵H"><a href="#计算基础矩阵F和单应矩阵H" class="headerlink" title="计算基础矩阵F和单应矩阵H"></a>计算基础矩阵F和单应矩阵H</h3><p>这里为了加速开了两个线程，下面分开介绍</p>
<h4 id="计算单应矩阵H"><a href="#计算单应矩阵H" class="headerlink" title="计算单应矩阵H"></a>计算单应矩阵H</h4><p>在函数<em>FindHomography()</em>中</p>
<p>首先进行对特征点进行归一化操作，这样尺度就获得了统一，计算结果具有更高的准确性。有关归一化的操作见基础知识。接下来对之前RANSAC的两百次随机采样的结果进行循环计算。在两百次循环中，干了一下这些事情：</p>
<ul>
<li>通过<em>ComputeH21()</em>函数计算归一化后的单应矩阵，计算完成后再通过之前归一化的转换矩阵的逆矩阵缩放回真实的单应矩阵。</li>
<li>利用重投影误差对当次的RABSAC结果进行评分，计算重投影并评分调用了<em>CheckHomography()</em>函数。</li>
<li>保存评分最高的单应矩阵并退出循环返回。</li>
</ul>
<p>关于<em>CheckHomography()</em>函数：</p>
<p>初始化操作中协方差系数<em>sigma</em>设置为1.0，因为只有一层图像</p>
<p>在单应矩阵中，重投影误差定义为从当前帧图像投影到参考帧图像的特征点匹配度和从参考帧图像投影到当前帧图像的特征点匹配度，具体表现为根据所求的单应矩阵求出从图1到图2的特征点，再计算投影到图2的点和图2对应的特征点之间的距离。</p>
<p>误差计算玩后和卡方检验的阈值进行对比，如果大于阈值就舍去，小于阈值就得分累加，就这样计算两遍（图1到图2和从图2到图1），最后返回得分。</p>
<h4 id="计算基础矩阵F"><a href="#计算基础矩阵F" class="headerlink" title="计算基础矩阵F"></a>计算基础矩阵F</h4><p>在函数<em>FindFundamental()</em>中</p>
<p>首先进行对特征点进行归一化操作，这样尺度就获得了统一，计算结果具有更高的准确性。有关归一化的操作见基础知识。接下来对之前RANSAC的两百次随机采样的结果进行循环计算。在两百次循环中，干了这些事情：</p>
<ul>
<li>通过<em>ComputeF21()</em>函数计算归一化后的单应矩阵，计算完成后再通过之前归一化的转换矩阵的逆矩阵缩放回真实的基础矩阵。</li>
<li>利用重投影误差对当次的RABSAC结果进行评分，计算重投影并评分调用了<em>CheckFundamental()</em>函数。</li>
<li>保存评分最高的基础矩阵并退出循环返回。</li>
</ul>
<p>关于<em>CheckFundamental()</em>函数：</p>
<p>初始化操作中协方差系数<em>sigma</em>设置为1.0，因为只有一层图像</p>
<p>在基础矩阵中，重投影误差定义为从当前帧图像投影到参考帧图像的特征点到极线的距离和从参考帧图像投影到当前帧图像的特征点到极线的距离，误差期望为0，到极线距离越远误差越大。</p>
<p>误差计算玩后和卡方检验的阈值进行对比，如果大于阈值就舍去，小于阈值就得分累加，就这样计算两遍（图1到图2和从图2到图1），最后返回得分。</p>
<h3 id="根据得分判断是用H还是F求解位姿"><a href="#根据得分判断是用H还是F求解位姿" class="headerlink" title="根据得分判断是用H还是F求解位姿"></a>根据得分判断是用H还是F求解位姿</h3><p>得分计算公式：</p>
<script type="math/tex; mode=display">
    RH=\frac{SH}{SH+SF}</script><p>SH是单应矩阵的评分，SF是基础矩阵的评分，如果RH&gt;0.4,就从单应矩阵恢复<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="3.54ex" height="1.984ex" role="img" focusable="false" viewbox="0 -683 1564.7 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"/></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(1203.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></svg></mjx-container>，如果RH&lt;0.4，就从基础矩阵恢复<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="3.54ex" height="1.984ex" role="img" focusable="false" viewbox="0 -683 1564.7 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"/></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(1203.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></svg></mjx-container>。恢复<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="3.54ex" height="1.984ex" role="img" focusable="false" viewbox="0 -683 1564.7 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"/></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(1203.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></svg></mjx-container>的函数分别为<em>ReconstructH()</em>和<em>ReconstructF()</em>。</p>
<h4 id="ReconstructH"><a href="#ReconstructH" class="headerlink" title="ReconstructH()"></a><em>ReconstructH()</em></h4><p>通过单应矩阵恢复位姿矩阵，有公式</p>
<script type="math/tex; mode=display">
   H=K(R-t\frac{n}{d})K^{-1}</script><p>其中K表示相机内参矩阵，n表示平面法向量，令中间的部分为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewbox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g></g></g></svg></mjx-container>，则有</p>
<script type="math/tex; mode=display">
   A=K^{-1}HK</script><p>这样求出矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewbox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"/></g></g></g></svg></mjx-container>，对其进行奇异值分解，得到</p>
<script type="math/tex; mode=display">
   A=UwV^{T}</script><p>得到8组解,<br>对8组解进行验证，选择产生相机前方最多3d点的一组解作为最优解并计算好点的数目。关于好点数目的计算调用了<em>CheckRT()</em>函数，最终把最优解的相关变量更新</p>
<p>关于<em>CheckRT()</em>函数：</p>
<p>首先将参考帧的坐标系定为世界坐标系，然后对所有的特征点对进行遍历，遍历做了以下行为：</p>
<ul>
<li>通过<em>Triangulate()</em>函数恢复3D点，该函数是利用三角化对点的深度进行估计；</li>
<li>检查通过三角化3D生成的三维点坐标是否无穷远，如果是无穷远点就跳过；</li>
<li>检查三维点的深度，求三维点和相机光心<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="6.434ex" height="2.032ex" role="img" focusable="false" viewbox="0 -704 2843.8 898"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mn" transform="translate(796,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g><g data-mml-node="mo" transform="translate(1199.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="msub" transform="translate(1644.2,0)"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"/></g><g data-mml-node="mn" transform="translate(796,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g></g></g></g></svg></mjx-container>的距离，同时根据余弦定理计算视差，如果深度小于0并且视差角过小也跳过；</li>
<li>计算三维点投影到两幅图像的重投影误差，这里直接通过针孔相机模型的公式计算，即</li>
</ul>
<script type="math/tex; mode=display">
   \begin{bmatrix} u\\v\\1 \end{bmatrix}=\frac{1}{Z}
   \begin{bmatrix} f_x&0&c_x\\0&f_y&c_y\\0&0&1 \end{bmatrix}
   \begin{bmatrix} X\\Y\\Z \end{bmatrix}</script><p>如果重投影误差太大，就跳过；</p>
<ul>
<li>累加好点（经过重重筛选幸存下来）的个数。</li>
</ul>
<p>如果好点数目大于0，就选一个较小的视差角并返回好点个数。如果没有好点就把视差角设0。</p>
<h4 id="ReconstructF"><a href="#ReconstructF" class="headerlink" title="ReconstructF()"></a><em>ReconstructF()</em></h4><p>通过分解本质矩阵计算得到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="3.54ex" height="1.984ex" role="img" focusable="false" viewbox="0 -683 1564.7 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"/></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"/></g><g data-mml-node="mi" transform="translate(1203.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"/></g></g></g></svg></mjx-container>，该操作调用函数<em>DecomposeE()</em>。根据本质矩阵分解原理会得到四组不同的解，但是只有一组是对的，所以要通过筛选进行判断。</p>
<p>通过<em>CheckRT()</em>检验得到的四组解，并选出最多好点的一组解进行判断。</p>
<p>如果好点数目优势不够明显就返回失败，如果通过考验就把相关解保存下来并指示初始化成功。</p>
<h3 id="创建初始化地图点"><a href="#创建初始化地图点" class="headerlink" title="创建初始化地图点"></a>创建初始化地图点</h3><p>如果上一步初始化成功了，首先把没有三角化的匹配点删除，然后将初始化后的第一帧作为世界坐标系，最后进行下列操作：</p>
<ul>
<li>将初始关键帧的描述子转换为词袋；</li>
<li>将关键帧插入地图；</li>
<li>遍历初始化的三维点，为这些三维点添加属性（还没学到这），最后插入到地图中，初始化完成。</li>
</ul>
]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV中用到的一些函数说明</title>
    <url>/2022/05/01/OpenCV%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<h2 id="取整函数"><a href="#取整函数" class="headerlink" title="取整函数"></a>取整函数</h2><p>cvRound()、cvFloor()、cvCeil()函数</p>
<ul>
<li>cvRound(): 返回参数最接近的整数值，四舍五入；</li>
<li>cvFloor(): 返回不大于参数的最大整数值，即向下取整；</li>
<li>cvCeil(): 返回不小于参数的最小整数值，即向上取整；</li>
</ul>
<p>示例：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    cout &lt;&lt; &quot;cvRound(2.5) : &quot; &lt;&lt; cvRound(2.5) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;cvFloor(2.5) : &quot; &lt;&lt; cvFloor(2.5) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;cvCeil(2.5)  : &quot; &lt;&lt; cvCeil(2.5)  &lt;&lt; endl;</span><br><span class="line">    </span><br><span class="line">    cout &lt;&lt; &quot;cvRound(2.5) : &quot; &lt;&lt; cvRound(2.5) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;cvFloor(2.5) : &quot; &lt;&lt; cvFloor(2.5) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;cvCeil(2.5)  : &quot; &lt;&lt; cvCeil(2.5)  &lt;&lt; endl;</span><br><span class="line">    </span><br><span class="line">    waitKey(0);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>运行结果如下</p>
<p><img src="/2022/05/01/OpenCV%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E8%AF%B4%E6%98%8E/1.png" alt="opencv"></p>
]]></content>
      <categories>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title>五一假期产生的一些感想</title>
    <url>/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/</url>
    <content><![CDATA[<p>北京的疫情又严重起来了，五一假期全都在实验室里坐着，每天除了不上课和平时基本没什么区别。最近在学习SLAM，想把学习过程中的一些想法记录下来，又不想拘泥于以前的做法，于是搭建了这个博客网站。不得不说框架真的是很方便，对于我这种对前端一无所知的人来说也能很快的搭好一个看上去还不错（个人感觉）的网站。</p>
<p>时常觉得自己还挺幸运的，因为对自己的专业，也就是自动化并不讨厌，甚至还挺喜欢，这样起码在学习的过程中不会觉得特别痛苦。大一入学的时候接触到了一些科创活动，碰到了一些很强的人，之后就顺理成章的一路走下来了。从大一寒假决定转专业到自动化，再到之后参加的各种比赛，大四考研，最后到现在的研究生，每一步好像都没有什么犹豫。本科在实验室的日子也是我在南航少数几段有声有色的时光。</p>
<p>本科做了三年的RoboMaster，这是大疆举办的一个全国性的机器人比赛，大一第一次见到这比赛的时候惊为天人，一瞬间就知道了自己想做的就是这玩意。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/3.jpg" alt="RoboMaster"></p>
<p>没有半点犹豫，我大一就进去拧了几个月螺丝，同时看看学长是怎么做的，说实话，那段激情燃烧的岁月还是挺值得留恋的，年轻人精力旺盛，一下子熬个几天夜不成问题，半夜的时候七八个人点个夜宵（那时候外卖还是可以直接送到楼下的），拿麦克纳姆轮搭成的半成品车架子当餐桌，凌晨三四点走在回宿舍的路上，校园里静悄悄的，连走路的脚步声都听的很清晰。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/1.jpg" alt="大一实验室的工作台"></p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/2.jpg" alt="半夜实验室夜宵"></p>
<p>暑假的时候队伍选拔新队员，我整个暑假大部分时间都在学校，只有中间回去了几天，小小缅怀了一下高中母校。当时选拔的题目是做一个倒立摆，那个时候我开始正式的学习STM32单片机，然后发现自己真的是很菜，调个PID都要调好久，遑论之前的底层驱动配置了。暑假的最后二十天整个人进入到一种很纯粹的状态，除了吃饭睡觉洗澡其他时间全在实验室里，终于在验收前几天实现了全部功能。验收的时候我惊讶的发现同时参加选拔的人有三分之二没做出来或者放弃选拔了，其中不乏之前看起来很强的大佬，因为他们高中就接触过类似的东西，而我的高中除了做题打游戏其他的啥也没有。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/4.jpg" alt="倒立摆"></p>
<p>做倒立摆的经历算是让我对电控真正的入了个门，同时也意识到做技术好像没有想象中的那么难，电脑也不全是用来打游戏的（误）。</p>
<p>新学期，我逐渐热衷于参加各种电子设计比赛，当时有一种冲动，想要通过做这些比赛来证明自己，现在看来做比赛有利有弊，好处是确实可以让你在比较短的时间内学到很多东西，坏处是很多东西并没有完全搞懂，浮于表面，毕竟做比赛拿来用，能解决问题就完事了。这个想法给我后面埋了很多坑，最突出的就是大四下学期出去实习画的板子前两版不能用。</p>
<p>大二一开始参加了校电赛，当时做了一个灯光遥控装置，刚一进去就拿了一等奖，这个比赛让我的自信心再一次爆炸，学习的欲望也随之更加旺盛。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/5.jpg" alt="校电赛"></p>
<p>因为这些比赛，我的大一和大二开始这段时间可谓是顺风顺水，大一学科成绩也在前10%，还有本硕连读资格，好像保研只是水到渠成的事情。当然，人生总是充满了戏剧性，校电赛结束后，我得了肺结核。</p>
<p>这场病直接毁了之前的一切。我在医院住了一个月，休学了两个月，大二上学期的课程上了一半全部退掉不让考试，堆叠到之后的学期。当医生和我说要住院一个月时我哭的梨花带雨，因为我担心这样会失去保研资格，现在想想当时的想法还挺好笑的。</p>
<p>大二下学期重新回到学校，课程负担已经因为转专业和休学，同时我又拒绝留级而增加到了一个恐怖的高度，我意识到我无论如何也不可能掌握全部的课程，同时还要做RoboMaster比赛，花一个暑假入的队不能就这么退了，所以我只认真学了在我看来有用的课，比如数电模电，比如信号与线性系统，比如计算机软硬件基础，毛概之类的课能不上就不上，这样整个学期的节奏就还在一个可以接受的范围内。最终我的综合成绩很差，顺理成章的失去了保研资格，但是我认真学了的几门课成绩都还可以，我觉得想要的知识学到就够了。</p>
<p>大二的RoboMaster我负责了一台步兵机器人的电控，这个比赛也是大二下学期做的，这一年的机器人都做得非常好，平时测试各种移动，自瞄都很稳，但是最后比赛的时候超级电容出了问题，这是整个队伍都疏忽的一点，挺可惜，但是也没有办法，只能认了。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/9.jpg" alt="步兵机器人"></p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/10.jpg" alt="战队合影"></p>
<p>可能生病只是一个开始，回来后我做的所有事情好像没有一件是成功的。大二暑假全国电赛寄了，本来想靠这个说不定能保研，大三做智能车也寄了，本来想靠这个说不定也能保研。每次校内赛选拔成绩都很好，比如校电赛和智能车的校内赛，智能车校内赛还拿了特等奖，最终比赛都因为莫名其妙的原因出了岔子。智能车另一个组的人拿了我校赛的代码，最后拿了国三。就这样磕磕绊绊过完了整个大三，八月份的时候决定考研。</p>
<p><img src="/2022/05/04/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%84%9F%E6%83%B3/11.jpg" alt="智能车"></p>
<p>考研那段时间仿佛又找回了从前当小镇做题家的日子，本科做的最后一件算是大一点的事没有出岔子，我如愿以偿来到了北航，然后意识到以前做的东西实验室基本上都不做（大悲），不过学新东西的感觉很好，未来的路也算是明了，起码自己想做什么方向还是有数的，这个程度我已经觉得算是满意了。</p>
<p>假期最后一天的晚上胡思乱想，翻来覆去睡不着，眼睛瞪得跟铜铃一样，脑子里就在回想这些东西。如果我因为从前的无法无天，不思进取要受到惩罚的话，那么我本科已经为此付出了相应的代价。研究生三年说不定就是学生生涯的结束了，希望这三年（只剩下两年多一点了）能够成长到想要的高度。</p>
<p>继续加油。</p>
]]></content>
      <categories>
        <category>杂记</category>
      </categories>
  </entry>
  <entry>
    <title>数学基础（一）：奇异值分解</title>
    <url>/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/</url>
    <content><![CDATA[<h3 id="奇异值分解SVD"><a href="#奇异值分解SVD" class="headerlink" title="奇异值分解SVD"></a>奇异值分解SVD</h3><p>SVD分解定义</p>
<script type="math/tex; mode=display">
   A=U\sum{}V^T</script><p>其中，A是$m\times n$的矩阵，根据奇异值分解后，U是$m\times m$的矩阵，$\sum{}$是一个$m\times n$的矩阵，除主对角线上的元素以外全部为0，主对角线上的每个元素都称为奇异值，V是一个$n\times n$的矩阵，U和V都是酉矩阵，即满足</p>
<script type="math/tex; mode=display">
U^TU=I,V^TV=I</script><p>可以用下图表示奇异值分解：</p>
<p><img src="/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/奇异值分解.png" alt="奇异值分解"></p>
<p>对于奇异值,它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。<br>也就是说，我们也可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说：</p>
<script type="math/tex; mode=display">
   A_{m\times n}=U_{m\times n}\sum{}_{m\times n}V^T_{n\times n}\approx U_{m\times k}\sum{}_{k\times k}V^T_{k\times n}</script><p>其中k比n小很多，也就是一个大矩阵A可以用三个小矩阵$U<em>{m\times k},\sum{}</em>{k\times k},V^T_{k\times n}$来表示。</p>
<p>SVD求解最小二乘问题：</p>
<script type="math/tex; mode=display">
   min\begin{Vmatrix}
      Ax-b
   \end{Vmatrix}^2,A\in R^{m\times n},x\in R^{n},b\in R^{m}</script><p>m个方程求n个未知数，有三种情况：</p>
<ul>
<li>$m=n$且A非奇异，则有唯一解（线性代数学到的）</li>
<li>$m&gt;n$，约束的个数超过未知数个数，称为超定问题</li>
<li>$m&lt;n$，约束的个数小于未知数个数，称为负定/欠定问题</li>
</ul>
<p>通常我们遇到的都是超定问题，此时是没有解的，从而转向最小二乘问题：</p>
<script type="math/tex; mode=display">
   J(x)=min\begin{Vmatrix}
      Ax-b
   \end{Vmatrix}^2</script><p>懒得敲公式了。上个链接<br><a href="https://zhuanlan.zhihu.com/p/436753966">奇异值分解与最小二乘法</a></p>
<p>总结一下结论，对于$Ax=0$</p>
<p>SVD分解之后得到的V最右侧的列向量(也就是$V^T最下方的行向量$)就是一般性齐次线性方程组$Ax=0$的解。</p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>数学基础（二）：卡方检验</title>
    <url>/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/</url>
    <content><![CDATA[<h3 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h3><p>卡方检验通过一个检验统计量来比较期望结果和实际结果之间的差别，然后得出观察频数极值的发生概率。<br>计算统计量步骤： （期望频数总和与观察频数总和相等）</p>
<ul>
<li>表里填写相应的观察频数和期望频数</li>
<li>利用卡方公式计算检验统计量：</li>
</ul>
<script type="math/tex; mode=display">
   \chi^2=\sum\frac{(O-E)^2}{E}</script><p>下面进行相关说明：</p>
<ul>
<li><p>O代表观察到的频数，也就是实际发生的频数。E代表期望频数。</p>
</li>
<li><p>检验统计量$\chi^2$意义：O与E之间差值越小，检验统计量越小。以E为除数，令差值与期望频数成比例。</p>
</li>
<li><p>卡方检验的标准：如果统计量值很小，说明观察频数和期望频数之间的差别不显著，统计量越大，差别越显著。</p>
</li>
<li><p>自由度：自由度用于计算检验统计量的独立变量数目，查表用的</p>
<p>自由度计算：对于单行或单列，自由度=组数-限制数；对于表格类，自由度=（行数-1）*（列数-1）</p>
</li>
</ul>
<p>卡方分布表如下所示</p>
<p><img src="/2022/05/09/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/卡方分布表.png" alt="卡方分布表"></p>
]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉系列（一）：图像金字塔</title>
    <url>/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/</url>
    <content><![CDATA[<h2 id="图像金字塔"><a href="#图像金字塔" class="headerlink" title="图像金字塔"></a>图像金字塔</h2><p>一幅图像的金字塔是一系列以金字塔形状排列，分辨率逐渐降低且源于同一张原始图的图像集合。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。层级越高，图像越小，分辨率越低。图像金字塔是图像中多尺度表达的一种，最初用于机器视觉和图像压缩，最主要功能用于图像分割，是一种以多分辨率来解释图像的有效但概念简单的结构。</p>
<p><img src="/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/1.jpg" alt="pyramid"></p>
<p>生成图像金字塔主要有两种方式： <strong>向下采样</strong>和<strong>向上采样</strong>。</p>
<ul>
<li>向下采样：将图像从最底层（即上图中的level0）转换为level1、level2…的过程，图像分辨率不断降低。</li>
<li>向上采样：将图像从最顶层（即上图中的level4）转换为level3、level2…的过程，图像分辨率不断增大。</li>
</ul>
<p>常见的金字塔一般有两类：</p>
<ul>
<li><strong>高斯金字塔</strong>: 用来向下/降采样，主要的图像金字塔；</li>
<li><strong>拉普拉斯金字塔</strong>: 用来从金字塔低层图像重建上层未采样图像，在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。</li>
</ul>
<p>在OpenCv中提供了对图像进行上下采样的接口：<strong>pyrUp()</strong>和<strong>pyrDown()</strong>，同时提供了一个对图像进行尺度变换的函数<strong>resize()</strong>。</p>
<p>获取金字塔一般来说包括两个步骤：</p>
<ul>
<li>对于向下采样，首先对图像进行高斯平滑，然后进行降采样（将图像尺寸行和列方向缩减一半）；</li>
<li>对于向上采样，首先对图像进行升采样（将图像尺寸行和列方向增大一倍），然后进行高斯平滑；</li>
</ul>
]]></content>
      <categories>
        <category>Computer Version</category>
      </categories>
      <tags>
        <tag>Computer Version</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉系列（三）：ORB特征点</title>
    <url>/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E7%82%B9/</url>
    <content><![CDATA[<h2 id="图像的特征点"><a href="#图像的特征点" class="headerlink" title="图像的特征点"></a>图像的特征点</h2><p>图像的特征点可以理解为图像中比较有代表性的点，这些点在相机视角发生少量变化后会保持不变，于是我们就可以在各个图像中找到相同的点。在SLAM的视觉里程计中，我们需要通过一帧帧连续拍摄的图像来对相机的运动进行估计，因此需要对每一帧图像中提取出特征点，通过这些点对相机的位姿估计进行讨论。</p>
<h2 id="ORB特征点"><a href="#ORB特征点" class="headerlink" title="ORB特征点"></a>ORB特征点</h2><p><strong>ORB特征点（Oriented FAST and Rotated BRIEF）</strong>是对<strong>FAST关键点</strong>和<strong>BRIEF特征描述子</strong>的一种结合与改进。</p>
<ul>
<li>FAST关键点是一种角点，主要检测局部像素区域灰度变化明显的地方，因为只检测亮度，所以速度非常快；</li>
<li>BRIEF是一种二进制描述子，在提取完关键点后，对每个关键点计算描述子，用来描述关键点周围像素的信息，描述子的设计原则是“ <strong>外观相似的特征应该具有相似的描述子</strong>”。</li>
</ul>
<p><img src="/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E7%82%B9/fast_speedtest.jpg" alt="FAST关键点"></p>
<p>虽然FAST关键点速度非常快，但是快有快的缺陷。首先，FAST关键点没有方向信息，因此当图像发生旋转之后，关键点对应的描述子会发生变化；此外，FAST关键点不具有尺度不变性，也就是说不同距离对着同一个物体拍照，远处看起来像关键点的地方，距离近了就可能不是关键点了。对于这两个问题，ORB特征点采用了如下方法进行解决。</p>
<ul>
<li>对于尺度问题，构建 <a href="https://kxzhang.cn/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/#more">图像金字塔</a>,得到不同尺度下的不同分辨率图像，对于每一层图像提取特征点，最后再匹配到原图像，这样就实现了关键点的尺度不变性；</li>
<li>对于旋转问题，ORB特征点采用了灰度质心法计算特征点的方向，通过特征点的方向实现关键点的旋转不变性。</li>
</ul>
<h2 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h2><p>OpenCV提取图像特征点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;chrono&gt;</span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">#define EDGE_THRESHOLD 19</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    std::vector&lt;cv::KeyPoint&gt; keypoints;</span><br><span class="line">    Mat descriptors;</span><br><span class="line">    cv::Ptr&lt;cv::FeatureDetector&gt; detector = cv::ORB::create();</span><br><span class="line">    cv::Ptr&lt;cv::DescriptorExtractor&gt; descriptor = cv::ORB::create();</span><br><span class="line"></span><br><span class="line">    Mat image = imread(&quot;../distorted.png&quot;, IMREAD_COLOR);</span><br><span class="line">    //-- 第一步:检测 Oriented FAST 角点位置</span><br><span class="line">    detector-&gt;detect(image, keypoints);</span><br><span class="line"></span><br><span class="line">    //-- 第二步:根据角点位置计算 BRIEF 描述子</span><br><span class="line">    descriptor-&gt;compute(image, keypoints, descriptors);</span><br><span class="line"></span><br><span class="line">    Mat outimg;</span><br><span class="line">    drawKeypoints(image, keypoints, outimg, cv::Scalar::all(-1), cv::DrawMatchesFlags::DEFAULT);</span><br><span class="line">    imshow(&quot;原图&quot;, image);</span><br><span class="line">    imshow(&quot;OpenCV函数提取的ORB特征点&quot;, outimg);</span><br><span class="line">    imwrite(&quot;OpenCV提取的ORB特征点.jpg&quot;, outimg);</span><br><span class="line">    waitKey(0);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<p><img src="/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E7%82%B9/distorted.png" alt="原图"></p>
<p><img src="/2022/05/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AORB%E7%89%B9%E5%BE%81%E7%82%B9/OpenCV提取的特征点.jpg" alt="OpenCV提取的特征点"></p>
]]></content>
      <categories>
        <category>Computer Version</category>
      </categories>
      <tags>
        <tag>Computer Version</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉系列（二）：图像梯度</title>
    <url>/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E6%A2%AF%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="图像梯度的概念"><a href="#图像梯度的概念" class="headerlink" title="图像梯度的概念"></a>图像梯度的概念</h2><p>图像梯度是指图像某像素在x和y两个方向上的变化率（与相邻像素比较），是一个二维向量，由2个分量组成X轴的变化、Y轴的变化。其中：</p>
<ul>
<li>X轴的变化是指当前像素右侧（X加1）的像素值减去当前像素左侧（X减1）的像素值；</li>
<li>Y轴的变化是当前像素下方（Y加1）的像素值减去当前像素上方（Y减1）的像素值；<br>计算出来这两个分量，会形成一个二维向量，该向量描述了当前像素点的梯度。对这个向量取反正切函数 <strong><em>arctan</em></strong> ，可以得到梯度的角度。</li>
</ul>
<h2 id="图像梯度的求解"><a href="#图像梯度的求解" class="headerlink" title="图像梯度的求解"></a>图像梯度的求解</h2><p>图像梯度的求解过程可以用一个卷积核来实现：[-1,0,1]。</p>
<p>$\nabla{f(x,y)}=$ $\left [ \begin{matrix} g_x\g_y \end{matrix} \right]=$ $\left [ \begin{matrix} \frac{\partial f}{\partial x}\ \frac{\partial f}{\partial y} \end{matrix} \right]=$ $\left [ \begin{matrix} f(x+1,y)-f(x-1,y)\f(x,y+1)-f(x,y-1) \end{matrix} \right]$</p>
<p><img src="/2022/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%9B%BE%E5%83%8F%E6%A2%AF%E5%BA%A6/2.png" alt="gradient"></p>
<p>$\nabla{f(x,y)}=$ $\left [ \begin{matrix} f(x+1,y)-f(x-1,y)\f(x,y+1)-f(x,y-1) \end{matrix} \right]=$ $\left [ \begin{matrix} 55-105\90-40 \end{matrix} \right]=$ $\left [ \begin{matrix} -50\ 50 \end{matrix} \right]$</p>
<p>图像梯度的绝对值为：</p>
<p>$\sqrt{50^2+(-50)^2}=70.7107$</p>
<p>图像梯度的角度为：</p>
<p>$\arctan(-50/50)=-45^\circ$</p>
]]></content>
      <categories>
        <category>Computer Version</category>
      </categories>
      <tags>
        <tag>Computer Version</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉系列（五）：基础矩阵和本质矩阵</title>
    <url>/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/</url>
    <content><![CDATA[<h3 id="对极几何"><a href="#对极几何" class="headerlink" title="对极几何"></a>对极几何</h3><p>先放一张图<br><img src="/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/对极几何示意图.png" alt="对极约束示意图"></p>
<p>设第一帧到第二帧的运动为$R,t$,两个相机中心分别为$O_1,O_2$。$p_1$是$I_1$中的特征点，对应到$I_2$中的特征点为$p_2$。下面通过一些术语来描述他们之间的几何关系。首先，连线$\vec{O_1 p_1}$和连线$\vec{O_2 p_2}$在三维空间中相交于$P$，这是$O_1,O_2,P$可以确定一个平面，称为极平面，$O_1,O_2$连线与像平面$I_1,I_2$的交点分别为$e_1,e_2$，$e_1,e_2$被称为极点，$O_1O_2$被称为基线，我们称极平面与两个像平面$I_1,I_2$之间的相交线$l_1,l_2$为极线。</p>
<h3 id="基础矩阵"><a href="#基础矩阵" class="headerlink" title="基础矩阵"></a>基础矩阵</h3><p>对于特征点对$p<em>1,p_2$，用基础矩阵$F</em>{21}$描述特征点对之间的转换关系</p>
<script type="math/tex; mode=display">
   p_2^TF_{21}p_1=0</script><p>写成矩阵形式，有</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} v_2&u_2&1 \end{bmatrix}
    \begin{bmatrix} f_1&f_2&f_3\\f_4&f_5&f_6\\f_7&f_8&f_9 \end{bmatrix}
    \begin{bmatrix} u_1\\v_1\\1 \end{bmatrix}=0</script><p>展开得到</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} u_1*u_2&v_1*u_2&u_2&u_1*v_2&v_1*v_2&v_2&u_1&v_1&1 \end{bmatrix}
    \begin{bmatrix} f_1\\f_2\\f_3\\f_4\\f_5\\f_6\\f_7\\f_8\\f_9 \end{bmatrix}=0</script><p>这样，每对点提供一个约束方程，基础矩阵共有9个元素，7个自由度，且秩为2，所以8对点提供8个约束方程就可以求解F。</p>
<h3 id="本质矩阵"><a href="#本质矩阵" class="headerlink" title="本质矩阵"></a>本质矩阵</h3><p>本质矩阵E和基础矩阵F差了个相机内参矩阵，恢复位姿的时候一般通过本质矩阵恢复，这样可以屏蔽因为相机内参造成的影响。本质矩阵和基础矩阵的关系为</p>
<script type="math/tex; mode=display">
   E=K^TFK , E=t^{\land}R</script><p>从本质矩阵恢复相机位姿$R，t$</p>
<p>对E进行奇异值分解（SVD），对于任意一个E，存在两个可能的$R，t$与其对应，又因为-E和E等价，所以对任意一个t取负号，得到的结果是一样的，因此通过本质矩阵E分解到$R，t$时，一共存在4个可能的解。幸运的是，正确的解是唯一的，只有第一个解的空间点P在两个相机中都具有正的深度。</p>
<script type="math/tex; mode=display">
   t_1^{\land}=UR_Z(\frac{\pi}{2})DU^T,R_1=UR^T_Z(\frac{\pi}{2})V^T</script><script type="math/tex; mode=display">
   t_2^{\land}=UR_Z(-\frac{\pi}{2})DU^T,R_2=UR^T_Z(-\frac{\pi}{2})V^T</script><p><img src="/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/本质矩阵分解1.jpg" alt="本质矩阵分解得到的四组解"></p>
<h3 id="三角测量（三角化）"><a href="#三角测量（三角化）" class="headerlink" title="三角测量（三角化）"></a>三角测量（三角化）</h3><p>已知一对匹配好的特征点$x_1,x_2$，投影矩阵$P_1,P_2$分别将同一个空间点X投影到两幅图中的$x_1,x_2$。</p>
<p>描述为：</p>
<script type="math/tex; mode=display">
   x_1=\lambda P_1X</script><script type="math/tex; mode=display">
   x_2=\lambda P_2X</script><p>对于每一个表达式可以用通用方程来描述：</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} x\\y\\1 \end{bmatrix}=\lambda
    \begin{bmatrix} p_1&p_2&p_3&p_4\\p_5&p_6&p_7&p_8\\p_9&p_10&p_11&p_12 \end{bmatrix}
    \begin{bmatrix} X\\Y\\Z\\1 \end{bmatrix}</script><p>简记为</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} x\\y\\1 \end{bmatrix}=\lambda
    \begin{bmatrix} -&P_0&-\\-&P_1&-\\-&P_2&-\end{bmatrix}
    \begin{bmatrix} X\\Y\\Z\\1 \end{bmatrix}</script><p>两边叉乘x，有</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} 0&-1&y\\1&0&-x\\-y&x&0 \end{bmatrix}
    \begin{bmatrix} -&P_0&-\\-&P_1&-\\-&P_2&-\end{bmatrix}
    \begin{bmatrix} X\\Y\\Z\\1 \end{bmatrix} =
    \begin{bmatrix} 0\\0\\0 \end{bmatrix}</script><p>一个点就有</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} yP_2-P_1\\P_0-xP_2\\xP_1-yP_0 \end{bmatrix}
    X =
    \begin{bmatrix} 0\\0\\0 \end{bmatrix}</script><p>秩为2，取前两行就够了</p>
<p>一对点的情况如下：</p>
<script type="math/tex; mode=display">
    \begin{bmatrix} y_1P_{12}-P_{11}\\P_{10}-x_1P_{12}\\y_2P_{22}-P_{21}\\P_{20}-x_2P_{22} \end{bmatrix}
    X =
    \begin{bmatrix} 0\\0\\0 \end{bmatrix}</script><p>变成最小二乘问题，用奇异值分解即可求解X</p>
<h3 id="各向同性归一化（八点法）"><a href="#各向同性归一化（八点法）" class="headerlink" title="各向同性归一化（八点法）"></a>各向同性归一化（八点法）</h3><p>利用8点法求基础矩阵不稳定的一个主要原因就是原始的图像像点坐标组成的系数矩阵A不好造成的，而造成A不好的原因是像点的齐次坐标各个分量的数量级相差太大。基于这个原因，在应用8点法求基础矩阵之前，先对像点坐标进行归一化处理，即对原始的图像坐标做同向性变换，这样就可以减少噪声的干扰，大大的提高8点法的精度。</p>
<p>预先对图像坐标进行归一化有以下好处：</p>
<ul>
<li>能够提高运算结果的精度</li>
<li>利用归一化处理后的图像坐标，对任何尺度缩放和原点的选择是不变的。归一化步骤预先为图像坐标选择了一个标准的坐标系中，消除了坐标变换对结果的影响。</li>
</ul>
<p>归一化操作分两步进行，首先对每幅图像中的坐标进行平移（每幅图像的平移不同）使图像中匹配的点组成的点集的形心（Centroid）移动到原点；接着对坐标系进行缩放使得点$p=(x,y,w)^T$中的各个分量总体上有一样的平均值，各个坐标轴的缩放相同的，最后选择合适的缩放因子使点p到原点的平均距离是$\sqrt{2}$。 概括起来变换过程如下：</p>
<ul>
<li>对点进行平移使其形心位于原点。</li>
<li>对点进行缩放，使它们到原点的平均距离为$\sqrt{2}$</li>
<li>对两幅图像独立进行上述变换</li>
</ul>
<p><img src="/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%9F%BA%E7%A1%80%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/归一化.png" alt="归一化"></p>
<p>上图左边是原始图像的坐标，右边是归一化后的坐标，H是归一化的变换矩阵，可记为如下形式：</p>
<script type="math/tex; mode=display">
   T=S
   \begin{bmatrix} 1&0&-\bar{u}\\0&1&-\bar{v}\\0&0&\frac{1}{S} \end{bmatrix}</script><p>其中，$\bar{u},\bar{v}$是图像点坐标两个分量的平均值</p>
<script type="math/tex; mode=display">
   \bar{u}=\frac{1}{N}\sum_{i=1}^N u_i,\bar{v}=\frac{1}{N}\sum_{i=1}^N v_i</script><p>S表示尺度，其表达式为：</p>
<script type="math/tex; mode=display">
   S=\frac{\sqrt{2}\cdot N}{\sqrt{\sum_{i=1}^N (u_i-\bar{u})^2+(v_i-\bar{v})^2}}</script><p><strong>注：这里的公式很多网上的博客都错了，分子的N应该在根号外面，这样平均距离才是$\sqrt{2}$,OpenCV的八点法归一化函数也是这样做的</strong></p>
<p>这样，首先对原始的图像坐标进行归一化处理，再利用8点法求解基础矩阵，最后将求得的结果解除归一化，得到基础矩阵F，总结如下：</p>
<ul>
<li>对图像1进行归一化处理，计算一个只包含平移和缩放的变换$T_1$，将图像1中的匹配点集$p_i^1$变换到新的点集$\hat{p_i^1}$，新点集的形心位于原点$(0,0)^T$，并且它们到原点的平均距离是$\sqrt{2}$。</li>
<li>对图像2，计算变换矩阵$T_2$进行相同的归一化处理</li>
<li>使用8点法利用变换后的点集估计基础矩阵$\hat{F}$</li>
<li>建立变换$F=T^T_2\hat{F} T_1$</li>
</ul>
<p>对单应矩阵的归一化处理同理，总结如下：</p>
<ul>
<li>对图像1进行归一化处理，计算一个只包含平移和缩放的变换$T_1$，将图像1中的匹配点集$p_i^1$变换到新的点集$\hat{p_i^1}$，新点集的形心位于原点$(0,0)^T$，并且它们到原点的平均距离是$\sqrt{2}$。</li>
<li>对图像2，计算变换矩阵$T_2$进行相同的归一化处理</li>
<li>使用8点法利用变换后的点集估计基础矩阵$\hat{H}$</li>
<li>建立变换$H=T^{-1}_2 \hat{H}T_1$</li>
</ul>
<p>ORB-SLAM2中的归一化操作与论文中的不同，是采取了一阶矩进行归一化，具体来说就是缩放因子分别为</p>
<script type="math/tex; mode=display">
   sX=\frac{N}{\sum_{i=1}^N \begin{vmatrix}u_i-\bar{u} \end{vmatrix}},
   sY=\frac{N}{\sum_{i=1}^N \begin{vmatrix}v_i-\bar{v} \end{vmatrix}}</script><p>至于为什么这样做，还没搞明白。</p>
]]></content>
      <categories>
        <category>Computer Version</category>
      </categories>
      <tags>
        <tag>Computer Version</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉系列（四）：单应矩阵</title>
    <url>/2022/05/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E5%8D%95%E5%BA%94%E7%9F%A9%E9%98%B5/</url>
    <content><![CDATA[<h3 id="单应矩阵"><a href="#单应矩阵" class="headerlink" title="单应矩阵"></a>单应矩阵</h3><p>单应矩阵约束了同一3D空间点在两个像素平面上的2D坐标，本质上是射影平面上的可逆齐次线性变换。对于特征点对$p_1,p_2$，用单应矩阵$H21$描述特征点对之间的变换关系，有：</p>
<script type="math/tex; mode=display">\begin{equation}
    p_2=H_{21}*p_1 \tag{1}
\end{equation}</script><p>其中$H_{21}$中的“21”表示从1到2的单应矩阵，也就是指“把坐标系2中的向量变换到坐标系1中”。下称矩阵形式，有</p>
<script type="math/tex; mode=display">
 \begin{equation} 
    \begin{bmatrix} u_2\\v_2\\1 \end{bmatrix}=
    \begin{bmatrix} h_1&h_2&h_3\\h_4&h_5&h_6\\h_7&h_8&h_9 \end{bmatrix}
    \begin{bmatrix} u_1\\v_1\\1 \end{bmatrix} \tag{2}
 \end{equation}</script><p> 两边左侧叉乘$p_2$，则等式左侧为0，右侧向量叉乘转换为反对称矩阵，得到下式</p>
<script type="math/tex; mode=display">
 \begin{equation} 
    \begin{bmatrix} 0&-1&v_2\\1&0&-u_2\\-v_2&u_2&0 \end{bmatrix}
    \begin{bmatrix} h_1&h_2&h_3\\h_4&h_5&h_6\\h_7&h_8&h_9 \end{bmatrix}
    \begin{bmatrix} u_1\\v_1\\1 \end{bmatrix}=0 
    \tag{3}
 \end{equation}</script><p>展开计算，有</p>
<script type="math/tex; mode=display">u_2=(h_1*u_1+h_2*v_1+h_3)/(h_7*u_1+h_8*v_1+h_9)</script><script type="math/tex; mode=display">
\begin{equation}  
   v_2=(h_4*u_1+h_5*v_1+h_6)/(h_7*u_1+h_8*v_1+h_9)
   \tag{4} 
\end{equation}</script><p>两边乘分母，得到</p>
<script type="math/tex; mode=display">h_1*u_1+h_2*v_1+h_3-(h_7*u_1*u_2+h_8*v_1*u_2+h_9*u_2)=0</script><script type="math/tex; mode=display">
\begin{equation}  
   -(h_4*u_1+h_5*v_1+h_6)+(h_7*u_1*v_2+h_8*v_1*v_2+h_9*v_2)=0
   \tag{5} 
\end{equation}</script><p>转化为矩阵形式，有</p>
<script type="math/tex; mode=display">
 \begin{equation} 
    \begin{bmatrix} u_1&v_1&1&0&0&0&-u_1*u_2&-v_1*u_2&-u_2\\0&0&0&-u_1&-v_1&-1&u_1*v_2&v_1*v_2&v_2 \end{bmatrix}
    \begin{bmatrix} h_1\\h_2\\h_3\\h_4\\h_5\\h_6\\h_7\\h_8\\h_9 \end{bmatrix}=0 
    \tag{6}
 \end{equation}</script><p>令第一项为$A$,第二项为$X$，则有</p>
<script type="math/tex; mode=display">
 \begin{equation} 
    AX=0
    \tag{7}
 \end{equation}</script><p>这样，每对特征点提供两个约束，$H$共有9个元素，由于变换是齐次的，所以同一个单应矩阵$H$可以相差一个非零常数因子，因此一个单应矩阵有8个自由度，理论上提供四对点形成8个约束方程就可以求解。</p>
<h3 id="通过单应矩阵恢复位姿-R-t"><a href="#通过单应矩阵恢复位姿-R-t" class="headerlink" title="通过单应矩阵恢复位姿$R,t$"></a>通过单应矩阵恢复位姿$R,t$</h3><p>从定义出发，单应矩阵通常描述处于共同平面的一些点在两张图像之间的变换关系。设图像$I_1,I_2$有一对匹配好的特征点$p_1,p_2$，这个特征点落在平面P上，设这个平面满足方程</p>
<script type="math/tex; mode=display">
   n^TP+d=0</script><p>整理得到</p>
<script type="math/tex; mode=display">
   -\frac{n^TP}{d}=1</script><p>又因为</p>
<script type="math/tex; mode=display">
   s_1p_1=KP,s_2p_2=K(RP+t)</script><p>有</p>
<script type="math/tex; mode=display">
   p_2\simeq K(RP+t)\simeq K(RP+t \cdot (-\frac{n^TP}{d}))\simeq K(R-\frac{n^T}{d}P\simeq K(R-\frac{tn^T}{d})K^{-1}p_1</script><p>从上面可以看出，单应矩阵$H_{21}$就是等式右边那一坨,设那一坨是A，A就包含了$R，t$的信息。</p>
<p>对H进行奇异值分解，会得到8组解$R,T$，选出3D点在相机前方最多的解为最优解</p>
<p>Q：为什么是八组解？</p>
<p>A：已知约束条件</p>
<ul>
<li>$d_1\ge d_2 \ge d_3$</li>
<li>$\sum_{i=1}^3x_i^2=1$ </li>
</ul>
<p>其中，$d_i$是奇异值，$x_i$是单位法向量n的坐标，所以平方和为1.</p>
<p>根据上面条件求解线性方程组，使其有非零解</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
\left(d^{\prime 2}-d_{2}^{2}\right) x_{1}^{2}+\left(d^{\prime 2}-d_{1}^{2}\right) x_{2}^{2}=0 \\
\left(d^{\prime 2}-d_{3}^{2}\right) x_{2}^{2}+\left(d^{\prime 2}-d_{2}^{2}\right) x_{3}^{2}=0 \\
\left(d^{\prime 2}-d_{1}^{2}\right) x_{3}^{2}+\left(d^{\prime 2}-d_{3}^{2}\right) x_{1}^{2}=0
\end{array}\right.</script><p>那么根据线性代数的知识可以知道，该线性方程组的行列式必须为0，即</p>
<script type="math/tex; mode=display">
   (d^{'2}-d_1^2)(d^{'2}-d_2^2)(d^{'2}-d_3^2)=0</script><p>逐个分析$d^{‘}$的取值</p>
<ul>
<li><p>$d^{‘}=\pm d_1$</p>
<p> 唯一解为:$x_1=x_2=x_3=0$，不满足第二个条件</p>
</li>
<li><p>$d^{‘}=\pm d_3$</p>
<p> 唯一解为:$x_1=x_2=x_3=0$，不满足第二个条件</p>
</li>
<li><p>$d^{‘}=\pm d_2且d_1 \ne d_3$</p>
<p> 有四组解：</p>
</li>
</ul>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
x_{1}=\varepsilon_{1} \sqrt{\frac{d_{1}^{2}-d_{2}^{2}}{d_{1}^{2}-d_{3}^{2}}} \\
x_{2}=0 \\
x_{3}=\varepsilon_{3} \sqrt{\frac{d_{2}^{2}-d_{3}^{2}}{d_{1}^{1}-d_{3}^{2}}}
\end{array}\right.</script><p>又，对于平移向量的公式</p>
<ul>
<li>$d^{‘}&gt;0$</li>
</ul>
<script type="math/tex; mode=display">
   t^{'}=(d_1-d_3)\begin{pmatrix}
      x_1 \\ 0 \\ -x_3     
   \end{pmatrix}</script><ul>
<li>$d^{‘}&lt;0$</li>
</ul>
<script type="math/tex; mode=display">
   t^{'}=(d_1+d_3)\begin{pmatrix}
      x_1 \\ 0 \\ x_3     
   \end{pmatrix}</script><p>可以看出，平移向量和每组解都有联系，因此就成了2*4=8组解，选出3D点在相机前方最多的解为最优解。</p>
]]></content>
      <categories>
        <category>Computer Version</category>
      </categories>
      <tags>
        <tag>Computer Version</tag>
      </tags>
  </entry>
</search>
